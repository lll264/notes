# 双重token机制

提高了安全性

自动续期，维护了长会话

# 项目

## gochat

前端不断向各个websocket连接发送心跳消息，更新每个节点的心跳消息

## bloghub

有啥亮点，怎么构建的，解决了什么问题，困难点在哪？用了什么框架？



怎么进行自我介绍，然后有这些情况可以考虑，不然的话就是要被瓦解

### 简单介绍

### 原理架构方式介绍

这个项目是一个博客发表与探讨的交流平台，总体采用微服务的架构，支持短信验证码和微信扫码等多种注册登录方式，用户具有文章修改发表阅读点赞收藏的功能，主要有评论、用户关系、搜索服务。用户可以关注自己喜欢的一些作者，还可以查看自己的粉丝。然后可以对文章进行动态的评论，也可以通过关键词或标签对文章进行检索。通过消息队列kafka降低服务之间的耦合性，每个独立的模块都是webcontroll层、逻辑层、存储层三层架构，通过wire工具按照依赖注入的原则编码，联系模块的各个层次，保证扩展性。然后的话项目通过docker部署第三方的依赖mysql/redis/消息队列等。然后的话项目还包含了我个人编写的一些工具库，包括数据迁移，滑动窗口限流算法这些。

### 问题/难点

#### mysql并发问题

##### 多次注册

前端多次点击注册的时候，后端可能插入了多条数据，遇到了并发问题，因为后端先查询数据是否存在，再去插入数据，可能多次请求同时查询到了数据不存在，然后都执行了插入。给账号添加一个唯一索引，然后也没有必要去查询，直接插入，然后通过唯一键冲突判断用户是否存在。

#### redis并发问题

##### 验证码发送问题

分布式情况下验证码生成和发送的并发问题，每次发送验证码都会先查询redis中对应手机号的验证码是否存在，先查询再发送验证码就可能导致多个请求同时查询到验证码不存在，然后都去生成验证码保存并发送，导致两次收到的验证码不一致，但redis的验证码是后保存的那个验证码，有一方验证一定会失败。

在不使用分布式锁的情况下，redis本身就能解决，redis是一个单线程模型，通过lua脚本把查询和修改操作作为一个整体执行，这样就解决了这个问题。另一方会提示发送太频繁。

还有就是验证码要考虑的很多，要防止攻击者暴力破解，同一个手机号码，一分钟以内只能发送一次。如果出现了多次验证失败，当前验证码直接不可用。一个验证码只能使用一次。

而且还要考虑一分钟发送一次，



### 亮点

#### 高内聚低耦合

每个模块都是一个独立的项目，耦合性低

#### 项目架构

使用wire工具，依赖注入来管理各个层次的联系

微服务单一职责，通过消息队列降低耦合

#### 日志接口

#### 熔断限流

采用了降级策略，以及客户端限流的措施保证系统的可用性

#### 设计模式

运用了各种设计模式，比如说短信登录层层封装。

#### TDD思想

项目采用了TDD思想

#### 微服务拆分

拆分流程

数据库迁移

流量控制转移

### 用户功能

#### 用户注册 sigup

输入账号密码，使用bcrypt进行密码加密，插入用户数据，通过账号唯一索引键冲突判断账号是否已经存在。

bcrypt不需要自己生成和保存盐值

#### 用户登录 loginJWT

根据账号查找用户，判断输入的密码是否正确。**通过redis限流限制登录尝试次数，频繁登录失败会锁定账户防止暴力破解。然后如果忘记密码，可以通过手机号找回。**

#### 使用长短token

登录成功后返回长短token给客户端，通过token鉴定用户信息。token通过带上客户端的useragent信息，鉴别伪造的token，进一步提高安全性。

#### 用户查询和修改个人信息 Profile/Edit

通过验证码更改或绑定手机号。

**缓存**

使用redis缓存用户信息，使用简单的string存储

```
set user:info:id json(domain.User) 15m
```

profile查询时先查询redis缓存，再查询数据库，为了保证数据一致性edit修改用户数据后，删除缓存。

#### 短信登录

通过接收验证码并向服务器验证从而提供一个快捷的注册或登录方式。redis保存验证码的同时，**限制验证码的发送次数以及有效时间**，比如说一分钟只能发送一次，防止暴力破解。然后**通过lua脚本将验证码检查与更新封装成一个整体操作，避免redis并发问题。**（假如有多个请求同时用一个手机号请求验证码，这些用户都收到了验证码，但是redis中一个手机号码只能保存一个验证码，所以只会有一个请求验证成功）

通过接口提供多个短信服务商，通过切片保存对应服务商，更改下标来使用不同的服务商，发送失败就使用下一个服务商，在保证短信发送的可用性的同时，也实现了短信任务在服务商之间的负载均衡。

被限流或服务商崩溃后，实行异步消息补发，消息转储数据库，后续通过goroutine获取补发。

##### 简单描述

首先定义一个发送短信的接口，提供不同服务商例如腾讯云或阿里云api的实现，实现发送短信的功能。

实现短信登录，包含验证码发送，校验验证码判断是否登录成功。通过随机数生成6位验证码存入redis，调用短信服务向对应手机号发送。后端接收输入的验证码查询redis校验。

注意短信发送一分钟只能发送一次，且校验失败3次后验证码直接无效。

装饰器模式通过滑动窗口算法进行限流

failover容错机制自动更换服务商（负载均衡做法），提高可用性。判断服务商崩溃通常是响应时间长、频繁收到超时响应，这里我们记录连续超时次数，连续超时次数大于阈值，切换当前服务商。

被限流或服务商崩溃后，实行异步消息补发，消息转储数据库，后续通过goroutine获取补发

##### 验证码发送 SendLoginSMSCode

获取手机号码，随机数生成6位验证码，存到redis中。通过短信服务发送到对应手机号。

redis使用string类型存储(phone_code:biz:xxxx)

```
set phone_code:login:189XXXXXXX 123456 10m
```

通过lua脚本首先查询对应手机号码的验证码是否存在，如果不存在或者存在且已经过了1分钟就保存验证码并发送，否则的话就发送太频繁。

##### 验证码登录 LoginSMS

后端获取到输入的验证码和手机号，通过lua脚本先查询redis中对应手机号验证码进行校验，然后当前验证码可用次数减1，如果可用次数为0，就删除当前验证码。

##### failover

用一个切片保存所有服务商，在短信发送失败后（send返回err），直接轮询其他服务商进行发送，然后有一个下标保存当前使用的服务商，每次短信发送后，下标都要移动，这样就实现了短信发送在这些服务商之间的负载均衡，提高了可靠性

##### 滑动窗口限流

每次执行请求的时候都会去判断是否要限流，通过redis的zset有序集合结构存每一个请求，member和score都存当前时间。每次执行请求的时候，就去查询时间范围窗口内的请求的个数，如果超过了阈值，就执行限流，直接返回响应。

```
count = zcount key now-window '+inf'
if count > threhold 
    限流
else 
    zadd key now now
```

##### 异步消息补发

**处理被限流的短信发送**

设计的比较简单，短信发送被限流或者发送失败后，就将这个短信保存到数据库中，然后有个后台goroutine不断获取数据库中的短信任务，进行短信的补发。

#### 微信扫码登录

##### 简单描述

用户点击微信登录，后台拼接appId，回调地址，state等参数返回调用地址，前端重定向显示二维码

扫码确认登录后微信回调后台得到了临时code，通过code带上appId和appSecret获取授权码登录成功。

state参数用于保持请求和回调的状态，当第一次跳转到微信的时候，后端带上一个state随机数区访问微信，并将这个随机数保存到客户端cookie中，来标识这一次会话，然后用户确认登录回调的时候就可以根据返回的state参数与cookie进行比较，判断是否是同一次会话。防止了攻击者伪造用户请求。

### 发帖功能

#### 新建或修改文章 Edit

插入或者修改制作库

#### 发表文章 Publish

三种情况，制作库和线上库都没有数据，制作库有线上库没有，制作库和线上库都有。

#### 作者查询文章列表 getByAuthor

#### 查看文章详情 getById/getPubById

分为作者查询制作库文章详情和读者查看线上库文章详情

#### 缓存

通过**string类型**进行缓存文章。

用户查看自己的文章列表大多数情况只会看第一页数据，因此可以只缓存用户的第一页文章，大多数情况就只会去读取redis缓存，article:first_page:uid，修改后删除缓存。

拿到列表之后，创作者有更大的概率会访问前几条数据。因此我们查询所有列表后，预缓存前几条数据的详情。article:pub:detail:id

文章发表后，可能就会有人立刻去访问，所以发表文章的同时，直接将文章添加到缓存中。article:detail:id

### 阅读点赞收藏

通过kafka异步进行处理，减少等待时间，消费者收集到一批请求后才去执行，减少数据库访问次数。

##### 缓存

用哈希表缓存每个文章的阅读点赞和收藏数量。不需要解决缓存一致性问题，因为性能损失更大。

### 榜单模型

不采用实时计算（扫描全表），热榜功能实现，通过cron-job异步定时维护热榜top100文章。

分批获取所有文章，通过小根堆数据结构维护热度前100数据，缓存直接用string类型存json字符串ranking:top_n 。获取到热榜数据后，先删除本地缓存，再更新redis缓存，查询榜单数据时先查询本地缓存，未命中再查找redis缓存并回写缓存。

**`延迟双删策略`解决缓存一致性问题**。直接删除本地缓存，在更新redis缓存，解决了多个榜单更新操作导致的数据不一致问题。但可能有读写并发的问题，也就是**删除本地缓存后可能会有查询请求重新回写旧的榜单数据，然后新的数据更新到redis当中，导致数据不一致的问题**。删除本地缓存后，延迟一段时间再次删除本地缓存，保证本地缓存一定被删除。

查询榜单是一个几十万并发量的接口，通过atomic包实现的本地缓存配合redis的双重缓存方案，实现了更高效的查询。去查询本地缓存，没找到再去查询redis缓存。为了进一步提高一点性能可以使用`缓存预加载`，在查询到榜单数据后，可以**提前缓存前几个帖子详情**。

### 不停机数据迁移

#### 简单描述

在拆分微服务的时候后，因为微服务数据库也是独立的，业务原本的数据就要同步过来，数据迁移如果暂停对用户就会有很大的影响，因此就要在不停机的情况下完成数据迁移，在数据迁移的过程中也会插入数据。

主要分成了四个阶段：

- 第一阶段读写源表，在这个阶段，你要完成目标表的数据初始化过程。
- 第二阶段是双写阶段，读写源表的同时还要写目标表，
- 第三阶段切换双写顺序，读写目标表，写源表
- 第四阶段开始读写目标表，完成数据迁移工作

在完成目标表数据初始化后，进行一次全量校验（会自动退出），尽量减少源表和目标表数据不一致的情况。然后进入双写阶段，双写阶段保持增量校验（传入utime，interval参数，只校验当前时间以后的数据，并且每隔一段时间间隔就执行校验），偶尔进行全量校验。

校验时如果出现数据不一致，就发送消息到kafka异步处理进行修复，通过队列保存需要修复大量的请求，然后让消费者慢慢的处理，保护了数据库，保证的系统的稳定性。而且解耦合，校验的业务不需要调用修复的业务，而是让修复的业务获取订阅消息自己执行。

#### 双写是怎么实现的？

gorm底层connpool的接口，gorm执行语句的时候会调用这个接口的方法。然后自己实现connpool集成对两个数据库表的操作。创建一个用于双写gorm数据库对象。

### 粉丝/关注 

数据库表存某个用户关注了另一个用户的关系

关注、取消关注、查看关注以及粉丝列表

### 用户评论

用户评论功能类似b站的评论，文章底下可以发表一些顶级的评论，然后这些顶级的评论下还可以发表评论。然后评论本身还可以被回复。

每条评论中，有一个rootID保存这条评论的根评论的id，一个pid保存父级评论的id

- create创建评论的时候，如果传入了pid，就表示是回复的某个评论
- delete删除评论时，可以直接删除这个评论，也可以通过pid=id，来删除所有子评论。
- GetCommentList分批次查询一批顶级评论，并查询对应3条子评论
- GetMoreReplies 根据根评论id查询这个顶级评论的所有子评论

```go
// Comment 把这个评论的表结构设计好
type Comment struct {
   Id int64 `gorm:"autoIncrement,primaryKey"`
   // 发表评论的人
   // 也就是说，如果你需要查询某个人发表的所有的评论，那么你需要在这里创建一个索引
   Uid int64
   // 被评价的东西
   // 这里要不要建索引？
   Biz     string `gorm:"index:biz_type_id"`
   BizID   int64  `gorm:"index:biz_type_id"`
   Content string

   // 我的根评论是哪个
   // 也就是说，如果这个字段是 NULL，它是根评论
   RootID sql.NullInt64 `gorm:"column:root_id;index"`

   // 这个是 NULL，也是根评论
   PID sql.NullInt64 `gorm:"column:pid;index"`

   ParentComment *Comment `gorm:"ForeignKey:PID;AssociationForeignKey:ID;constraint:OnDelete:CASCADE"`

   Ctime int64
   // 事实上，大部分平台是不允许修改评论的
   Utime int64
}
```

### 标签搜索

用户可以创建或为文章添加标签，并且同步到elasticsearch中，搜索的时候，根据输入的内容拆分出关键词，通过关键词检索出标签，标题，内容包含这些关键词的文章。

### 原理

#### 什么是跨域问题？跨域问题怎么解决的？

#### jwt原理？为什么使用jwt？为什么使用长短token?

jwt它由头部、负载、签名组成，通过对头部和负载生成签名来验证jwt的完整性，确保jwt不会被篡改。

但使用jwt安全性风险很大，因为秘钥可能泄露，泄露后攻击者可以自己生成jwt。

jwt不依赖第三方存储，比如session在分布式环境下，可能要通过redis来存储，每次请求都要查询redis影响性能

**长短token**

登录成功后给用户返回两个token，过期时间一个长一个短，使用短的jwt**一定程度上提高了安全性，防止token泄露**。让前端长token刷新短token