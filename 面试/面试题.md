# MySQL

## 基础

### 1.MySQL的执行流程

- **建立连接**：tcp三次握手，有长连接与短连接之分
- **查询缓存**：根据sql语句先去缓存中查找结果，找到了直接返回结果，没找到
- 就继续执行。MySQL 8.0 版本直接将查询缓存删掉了
- **解析SQL**：
  - 词法分析，提取出SQL语句中的关键字
  
  - 语法分析，根据提取出的关键字判断输入的sql语句是否满足mysql语法规则
- **执行SQL**：
  - 预处理：例如select * 中的 * 符号，扩展为表上的所有列
  
  - 优化：例如索引的最优选择
  - 执行：磁盘查询数据

### 2.InnoDB Compat行格式

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/row_format/COMPACT.drawio.png" alt="img"  />

**记录的额外信息**

- **变长字段长度列表**：记录各个变长字段varchar(n)真实占用字节数

- **NULL值列表**：每个非NOT NULL字段组成的二进制bit位，1表示为NULL,0表示不是NULL。注意NULL 值列表必须用整数个字节的位表示（1字节8位），如果使用的二进制位个数不足整数个字节，则在字节的高位补0。`当数据表的字段都定义成 NOT NULL 的时候，这时候表里的行格式就不会有 NULL 值列表了`。

- **记录头信息**：包含多个字段，delete_mask、delete_mask，record_type等

**记录的真实数据**

  **包含三个隐藏字段和记录中每个列的值**

  - row_id 如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。
  - trx_id 这个数据是由哪个事务生成的，占用 6 个字节
  - roll_pointer 记录上一个版本的指针。占用 7 个字节

### 3.Buffer Pool缓存什么？

Buffer Pool 是MySQL的缓存

- **当读取数据时**，如果数据存在于 Buffer Pool 中，客户端就会**直接读取** Buffer Pool 中的数据，否则再去磁盘中读取。
- **当修改数据时**，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，**然后将其页设置为脏页**（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。

在 MySQL 启动的时候，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间（虚拟空间），然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。**

Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页等等。

## 索引

### 1.什么是索引？

简单来讲，索引就是一种**将数据库中的记录按照特殊形式存储的数据结构**。通过索引，能够显著地提高数据查询的效率，从而提升服务器的性能。

专业一点来说，索引是一个**排好序的列表**，在这个列表中**存储着索引的值和包含这个值的数据所在行的物理地址**

### 2.聚簇索引，二级索引，联合索引

**聚簇索引与二级索引**

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据，**要进行回表**。

**覆盖索引**

在查询时使用了二级索引，**如果查询的列能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引**。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，**获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表**。

**联合索引**

使用**最左匹配原则**（从第一个字段开始不能跳跃），遇到范围查询会停止覆盖。

**索引下推**

在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

### 3.InnoDB 数据页格式，B+树查找过程

InnoDB 的数据是按「数据页」为单位来读写的，数据页的默认大小是 16KB

对于每个节点中的查找，每一页包含一个**页目录**，所有的记录被分为了多组，页目录用来存储每组最后一条记录的地址偏移量（槽），**页目录就是由多个槽组成的，槽相当于分组记录的索引**，通过**二分查询**的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录，起到记录的索引作用。

**找到对应记录后就可以定位到下次层中的页节点**，直到叶子节点

### 4.讲一讲索引数据结构，为什么使用B+树？

**hash表**，hash表等值查询效率高，时间复杂度O(1)。因为存储的是hash码，无法排序，所以不支持范围查询，只能全表扫描。可能会有hash冲突，发生冲突时，查询效率可能极差。

**二叉搜索树**，有序，利用二分查找定位数据，但是它存在一种极端的情况，就会导致二分查找树**退化成一个链表**，此时查询复杂度就会从 O(logn)降低为 O(n)。

**平衡二叉树**。它解决二分查找树退化成链表的问题。但是它**本质上还是一个二叉树**，每个节点只能有 2 个子节点，随着元素的增多，**树的高度会越来越高**，**磁盘io次数也越多**。

**B树和B+树，**都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。

- **B+ 树的非叶子节点不存放实际的记录数据，仅存放索引**，因此数据量相同的情况下，相比存储只存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 **B+ 树可以比 B 树更「矮胖」**，查询底层节点的磁盘 I/O次数会更少。
- **B+ 树有大量的冗余节点**（**叶子节点包含了非叶子节点中的索引**），这些冗余索引让 B+ 树在**插入、删除的效率都更高**，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
- **B+ 树节点之间用双向链表连接了起来**，**有利于范围查询**，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。

### 5.索引优缺点，什么时候需要/不需要索引？

**缺点**

- 需要**占用物理空间**，数据数量越多，索引占用空间越大；
- **创建索引和维护索引**要耗费时间，这种时间随着数据量的增加而增大；
- 会**降低表的增删改的效率**，因为每次增删改数据时都要修改索引，B+ 树为了维护索引有序性，都需要进行动态维护。

只有经常使用where查询的字段才建立索引，提高查询性能。以下情况不建立索引

- **表记录太少**
- **经常更新的字段**不用创建索引，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的
- **字段中存在大量重复数据且分布平均，不需要创建索引**，假如一个表有10万行记录，有一个字段A只有T和F两种值，且每个值的分布概率大约为50%，那么对这种表A字段建索引一般不
  会提高数据库的查询速度。

### 6.索引优化方式？

#### 前缀索引优化

前缀索引顾名思义就是**使用某个字段中字符串的前几个字符建立索引**，那我们为什么需要使用前缀来建立索引呢？

**使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值**，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。

不过，前缀索引有一定的局限性，例如：

- order by 就无法使用前缀索引；
- 无法把前缀索引用作覆盖索引；

#### 覆盖索引优化

**在使用二级索引的时候尽量达到一个索引覆盖的效果**

覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。

假设我们只需要查询商品的名称、价格，有什么方式可以避免回表呢？

我们**可以建立一个联合索引**，即「商品ID、名称、价格」作为一个联合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而**避免回表**。

所以，使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。

#### 使用自增主键

**如果我们使用自增主键**，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次**插入一条新记录，都是追加操作，不需要重新移动数据**，因此这种插入数据的方法效率非常高。

**如果我们使用非自增主键**，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会**插入到现有数据页中间的某个位置**，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为**页分裂**。`页分裂`**还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率**。

### 7.索引失效有哪些情况？

- 联合索引要能正确使用需要遵循**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。

- 当我们使用**左或者左右模糊匹配**的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 当我们在查询条件中**对索引列使用函数**，就会导致索引失效。`where length(name)=6;`
- 当我们在查询条件中**对索引列进行表达式计算**，也是无法走索引的。`where id+1=10;`
- MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于**隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数**，所以就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而**在 OR 后的条件列不是索引列，那么索引会失效。**

## 事务

### 1.说说ACID

**原子性（Atomicity）**：一个事务中的操作要么全部成功，要么全部失败，不能只完成一部分

**一致性（Consistency）**：数据从一个一致性的状态转移到另一个一致性的状态,不会存在中间状态，数据满足完整性约束

**隔离性（Isolation）**:数据库允许多个并发事务同时对其数据进行读写和修改的能力

**持久性（Durability）**：事务处理结束后，对数据的修改就是永久的

### 2.并行事务会引发什么问题？

**脏读**

如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。

**不可重复读**

在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。`数据修改了`，（事务可能修改数据并提交了）

**幻读**

在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。`新增或删除了数据`

### 3.事务的隔离级别，InnoDB使用哪种级别？

- **读未提交（read uncommitted）**，指一个事务还没提交时，它做的变更就能被其他事务看到；
- **读提交（read committed）**，指一个事务提交之后，它做的变更才能被其他事务看到；**避免了脏读**
- **可重复读（repeatable read）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的。**避免了可重复读**
- **串行化（serializable）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；**避免了幻读**

InnoDB使用的是可重复读级别

### 4.幻读是怎么解决的？

- 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
- 针对**当前读**（select ... for update 等语句），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。

### 5.MVCC（原理，优点）

**原理**

`trx_id`记录最后修改该记录的事务id。每次对记录进行修改后，就会把旧版本的数据存进`undo日志`中，而`roll_pointer指针`指向每一个旧版本记录，于是就可以通过它找到修改前的记录。

读提交隔离级别是在**每个快照读执行前都会重新生成一个 `Read View`，**而可重复读隔离级别**是启动事务时生成一个 Read View，**然后整个事务期间都在用这个 Read View。

通过Read View中的活跃事务id和undo日志中的旧版本数据就可以解决幻读问题。

**优点**

读不加锁，读写不冲突，极大的增加了系统的并发性能

## 锁

### 1.MySQL锁的作用以及各种锁分类

当数据库有并发事务的时候，可能会产生数据的不一致，锁的作用是解决并发问题。

**从使用性质上**分为共享锁/读锁/S和排他锁/写锁/X

**从锁粒度上**分：表级锁，行级锁：记录锁（Record Lock）间隙锁（Gap Lock）临键锁（Next-Key Lock）

**从主观上**分为：

乐观锁：从主观上认定资源是不会被修改的，所以不加锁读取数据

悲观锁：每次读取数据时都会认为会被其它事务修改，所以每次操作都需要加上锁。

### 2.什么是快照读和当前读

快照读就是读取的是快照数据，不加锁的简单 Select 都属于快照读。

```mysql
SELECT * FROM player WHERE ...
```

当前读就是读的是最新数据，而不是历史的数据。**加锁的SELECT**，或者对数据进行增删改都会进行当前读。

```mysql
SELECT * FROM player LOCK IN SHARE MODE;
SELECT FROM player FOR UPDATE;
INSERT INTO player values ...
DELETE FROM player WHERE ...
UPDATE player SET ...
```

**当前读会给数据加锁**

## 日志

### 1.讲一讲三种日志

#### undo log

每当对数据进行修改（增、删、该）前，会把旧版本的数据都记录到undolog中，用于回滚。

undo log 会写入 Buffer Pool 中的 Undo 页面。在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作

**两大作用：**

- **实现事务回滚，保障事务的原子性**。事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。
- **实现 MVCC（多版本并发控制）关键因素之一**。MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。

#### redo log

当对某页进行修改后，会将这个页的修改**以 redo log 的形式记录下来**（对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新）

Buffer Pool在内存中，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。`而先写redo log到磁盘就可以避免这个问题，从而实现数据的持久化` 

**刷盘时机**

redo log会先缓存在redo log buffer中，一般当事务提交后由后台线程刷盘

#### binlog

MySQL在完成一条更新操作后，Server层会生成一条binlog，**binlog 文件是记录了所有数据库表结构变更和表数据修改的日志**，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。

binlog主要用于主从复制

### 2.主从复制（定义，原理）

**主从复制**是用来建立一个与主数据库完全一样的数据库环境，即从数据库。主数据库一般是准实时的业务数据库。

**原理**

binlog 二进制文件，记录了数据可执行的所有 SQL 语句。主从同步的目标就是把主数据库的 binlog 文件中的 SQL 语句复制到从数据库，让其在从数据的 relaylog 文件中再执行一次这些 SQL 语句即可。

需要三个线程：

**binlog输出线程**：每当有从库连接到主库时，主库都会创建一个binlog输出线程然后发送 binlog内 容到从库

**从库IO线程：**当 `START SLAVE` 语句在从库开始执行之后，从库创建一个 IO 线程，该线程连接到主库并接收binlog 里面的更新记录到从库中的relay log中继日志中

**从库 SQL 线程**：回放binlog，更新数据，实现主从数据库一致性

## 其他问题

### 1.MySQL优化

避免索引失效，走全表

尽量不要使用select *，只要读取需要的字段

### 分库分表

# Redis

## 认识Redis

### Redis是什么？

Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。

### 常用数据类型内部实现及应用场景

**string**

内部有**int和SDS动态字符串**实现，常用于：

- 缓存对象：存对象的json，set user:1 '{"name":"xiaolin", "age":18}'
- 常规计数：
- 分布式锁：

**list**

内部由**双向列表和压缩列表实现（3.2版本quicklist）**，常用于：

- 消息队列

**hash**

内部由**哈希表和压缩列表**实现，常用于：

- 缓存对象：set user name:zs age:10
- 购物车：用户 id 为 key，商品 id 为 field，商品数量为 value

**set**

内部由**哈希表和整数集合**实现，常用于：

- 点赞：因为不能重复点赞，为每个文章存点赞用户id，sadd article:1 user:1
- 共同关注：集合运算，交集计算

**zset**

内部由**压缩列表或跳表（3.2版本listpack）**实现，常用于：

- 排行榜：
- 电话姓名排序（字典排序）：

## redis线程模型

### redis是单线程吗？

Redis 单线程指的是「**接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端**」这个过程是由一个线程（主线程）来完成的，这也是我们常说Redis 是单线程的原因。但是，Redis 程序并不是单线程的，Redis 在启动的时候，是会启动后台线程

### redis单线程为什么还那么快？

- Redis 的**大部分操作 都在内存中完成** ，并且采用了高效的数据结构，因此 Redis瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；
- Redis 采用单线程模型可以 **避免了多线程之间的竞争** ，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
- Redis 采用了 I/O 多路复用机制 处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

## 持久化

### 1.AOF日志（原理、缺点）

Redis 每执行一条写操作命令，就把该命令以追加的方式写入到AOF日志中，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。

**风险:**

- **数据可能会丢失**： 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。
- **可能阻塞其他操作**： 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，可能会阻塞后续的操作无法执行。

### 2.AOF写回策略

redis执行完写命令后，会将命令追加到 `server.aof_buf` 缓冲区；

然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 **AOF文件内核缓冲区 page cache**，等待内核将数据写入硬盘；具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。

三种写回策略：

- **Always**，每次**写操作命令执行完后，同步将 AOF 日志数据写回硬盘；主进程会阻塞**
- **Everysec**，所以它的意思是每次写操作命令执行完后，先将命令**写入到 AOF 文件的内核缓冲区，然后子线程异步执行每隔一秒将缓冲区里的内容写回到硬盘**；
- **No**，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令**写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。**

### 3.AOF重写机制

**原理**

随着写命令越来越多，AOF文件会越来越大。当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。

重写方法是将所有对某个键值对的修改命令更新为最新的对其修改的命令。

**后台重写**

重写比较耗时，所以重写的操作不能放在主进程里。Redis 的**重写AOF过程是由后台子进程 bgrewriteaof 来完成的**

**写时复制**

在创建子进程进行重写时，只会复制页表而共享同一块内存，**只有在发生修改内存数据的情况时，物理内存才会被复制一份**，减少创建子进程时的性能损耗，从而加快创建子进程的速度。

**AOF重写缓冲区**

在重写AOF日志过程中，如果主线程修改了数据，那么主线程和子线程的数据就不一致了。

当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。子线程在重写完原本的数据后，就将AO 重写缓冲区中的所有内容追加到新的 AOF 的文件中。

### 4.RDB 快照是如何实现的呢？

将redis中的数据写入到RDB文件中来实现持久化，每次执行快照，都是把内存中的所有数据都记录到磁盘中，Redis 提供了两个命令来生成 RDB 文件，分别是 `save` 和 `bgsave`分别使用主线程和后台线程生成RDB快照。

bgsave快照过程中，主线程修改数据发生**写时复制**时，RDB快照保存的是原本的数据，而主线程刚修改的数据，是没办法在这一时间写入 RDB 文件的，只能交由下一次的bgsave快照。

### 5.混合持久化机制

RDB 优点是**数据恢复速度快，但是快照的频率不好把握**。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。

AOF 优点是**丢失数据少，但是数据恢复不快**。

为了集成了两者的优点， Redis 4.0 提出了混合使用 AOF 日志和内存快照，也叫混合持久化，AOF文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。**既保证了 Redis 重启速度，又降低数据丢失风险**

## 功能篇

### 1.过期删除怎么实现的？

Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。

字典实际上是哈希表，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找。当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期

**三种删除策略**

**定时删除：**在设置key的过期时间时，同时设置一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。

- 内存可以被尽快地释放
- 占用相当一部分 CPU 时间

**惰性删除：**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key

- 对 CPU 时间最友好。
- 如果过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费

**定期删除：每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key**

- 减少了删除操作对 CPU 的影响，同时减少了过期键对空间的无效占用。
- 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。

**Redis 选择「惰性删除+定期删除」这两种策略配和使用**，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

### 2.内存淘汰策略

当redis内存满了后，内存淘汰策略删除符合条件的 key。具体有8中内存淘汰策略

- 不进行数据淘汰，而是不再提供服务，直接返回错误

在过期时间数据中进行淘汰：

- 随机淘汰设置了过期时间的任意键值
- 优先淘汰更早过期的键值
- 淘汰所有设置了过期时间的键值中，最久未使用的键值（lru）
- 淘汰所有设置了过期时间的键值中，最少使用的键值(lfu)

在所有数据中进行淘汰：

- 随机淘汰任意键值
- 淘汰整个键值中最久未使用的键值（lru）
- 淘汰整个键值中最少使用的键值。(lfu)

### 3.Redis持久化怎么处理过期键的？

RDB方式再生成RDB文件时，会直接忽略已过期的键

AOF方式下，对于已过期键写入redis命令时，会加入一条del命令显示删除该键

### 4.主从模式下怎么处理过期键的？



## 高可用

### 1.Redis 如何实现服务高可用？

主从复制、哨兵、集群

### 2.主从复制（意义、策略）

如果数据只存储在一台服务器上，硬盘出现了故障，可能数据就都丢失了。要避免这种单点故障，最好的办法是将数据备份到其他服务器上。**主从复制**解决了多台服务器之间的数据一致性问题。

**主从复制策略**

首先建立连接进行第一次同步，也是**全量同步**，主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器

完成第一次同步后，双方之间就会维护一个 TCP 连接。主服务器可以继续将写操作命令传播给从服务器，即**增量同步**

**增量同步失败可能是因为网络断开，从服务器与主服务器断开连接，而从服务器需要的同步缓冲已经被覆盖了。**然而主服务器任何时候都可以发起全量同步，其主要策略就是无论如何首先会尝试进行增量同步，如果失败则会要求 slave 进行全量同步。

### 3.哨兵模式原理

**哨兵**其实是主从模式下一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。

**监控**

哨兵可以监控所有主从节点，判断它们是否正常运行。如果监控到主节点无响应，哨兵就会判断其为**主观下线**。然后向其它哨兵发起投票，达到某一票数后，主节点就会被标记为**客观下线**

**选主**

然后就通过vote投票算法从所有节点中再选出一个主节点。更改相关配置

**通知**

哨兵会通过发布者/订阅者模式通知客户端主节点已经发生变化。客户端就可以跟新主节点进行通信了。

## 缓存

### 1.什么是缓存雪崩、缓存击穿、缓存穿透，各自怎么解决？

#### 缓存雪崩

**大量缓存数据在同一时间过期 或者 Redis 故障宕机**，大量请求直接访问数据库，从而导致数据库压力骤增，严重导致数据库宕机。

- 均匀设置过期时间；
- **如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存**
- 缓存不设置有效期，而是**让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新**。
- 启动**服务熔断**机制，**暂停业务应用对缓存服务的访问，直接返回错误**

#### 缓存击穿

**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，**数据库很容易就被高并发的请求冲垮**

同雪崩

- 启动**服务熔断**机制，**暂停业务应用对缓存服务的访问，直接返回错误**
- 不给热点数据设置过期时间
- 互斥锁

#### 缓存穿透

当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，**数据库的压力骤增**，这就是缓存穿透的问题。

- **缓存空值或者默认值**，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样**后续请求就可以从缓存中读取到空值或者默认值**，返回给应用，而不会继续查询数据库。
- 非法请求的限制，在 API 入口处我们要判断求请求参数是否合理
- **使用布隆过滤器快速判断数据是否存在**，避免通过查询数据库来判断数据是否存在。

### 2.布隆过滤器简单原理

快速判断数据是否在数据库中，而不用去查询

布隆过滤器会通过 3 个操作完成标记：

- 第一步，使用 **N 个哈希函数分别对数据做哈希计算**，得到 N 个哈希值；
- 第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。
- 第三步，将每个哈希值**在位图数组的对应位置的值设置为 1**；

例如当应用要查询数据 x 是否数据库时，通过布隆过滤器的3个哈希函数得到3个哈希值，再得到位图数组的3个位置，只要查到位图数组的这3个位置的值是否全为 1，**只要有一个为 0，就认为数据 x 不在数据库中**。

### 3.缓存一致性问题?（先删后写还是先写后删）

在更新数据时，无论是先更新数据库，再更新缓存，还是先更新缓存，再更新数据库，这两个方案都可能会出现缓存和数据库中的数据不一致的现象。因此不更新缓存，而是删除缓存中的数据。

**先删缓存后写DB**：

**产生脏数据的概率较大**（若出现脏数据，则意味着再不更新的情况下，查询得到的数据均为旧的数据）。

比如两个并发操作，一个更新一个查询，当更新操作删除缓存后还没有修改数据库，查询操作未命中查询数据库后将数据读取到了缓存中，然后更新操作这时修改了数据库，**缓存与数据库数据不一致**

**先写DB再删缓存**：

**产生脏数据的概率较小，但是会出现一致性的问题**；若更新操作的时候，同时进行查询操作并命中，则查询得到的数据是旧的数据。但是不会影响后面的查询。

并发操作，一个读一个写，首先缓存无数据读取未命中，在将数据库数据读取到缓存之前，写操作修改了数据库并删除缓存后，读操作将旧数据读到缓存，**缓存与数据库数据不一致**，但出现概率较小。

`所以，先更新数据库再删除缓存的方案，是可以保证数据一致性的`



# 网络

## HTTP

### 1.http请求格式

请求行：GET /index.jsp HTTP/1.1  （请求方法 URL 协议/版本）

请求头（Header）：由多个“key:val”对组成

请求体（Body）：GET请求没有，对于POST请求，请求正文用于提交的数据

### 2.http常见状态码以及常见字段

**http常见的状态码**

- `1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态
  - 101 切换请求协议
- `2xx` 类状态码表示服务器**成功**处理了客户端的请求
  - 200 OK 请求成功
- `3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。
  - 301 永久重定向，请求的资源已经不存在了
  - 302 临时重定向，请求的资源还在
- `4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。
  - 400 请求错误
  - 404 请求资源在服务器上不存在或未找到
- `5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

**http常见字段**

`Host字段`，客户端发送请求时，用来指定服务器的域名。

`Content-Length` 字段，表明本次回应的数据长度。

`Connection` 字段最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。

`Content-Type` 字段用于服务器回应时，告诉客户端，本次数据是什么格式。

`Content-Encoding` 字段说明数据的压缩方法。

### 3.get和post方式的区别

- get请求参数直接以查询字符串的形式拼接在请求行中的url中，post请求参数在请求体中。URL只支持Ascii编码，因此get参数只支持Ascii码，且有长度限制
- get方式是安全且幂等的，而post方式是不安全且不幂等的

**`安全性`：在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。**

**`幂等性`：所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。**

### 4.DNS寻址

根据输入的域名首先查找浏览器或操作系统有没有这个域名的缓存

没有就向本地域名服务器发起DNS请求，如果本地域名服务器能找到对应IP就直接返回，否则就要想根域名服务器发起DNS请求。

根域名服务器收到来自本地 DNS 的请求后，根据请求中的域名后缀，提供顶级域名服务器的地址

本地域名服务器再次向顶级域名服务器发送一个递归查询请求

顶级域名服务器收到递归查询请求后，根据请求中的域名提供权威域名服务器的IP地址

本地域名服务器再次向权限域名服务器发送一个递归查询请求

权威域名服务器查询后将对应的IP地址告诉本地DNS，本地 DNS 再将 IP 地址返回客户端

### 4.Session、Cookie、Token

session：当用户客户端第一次访问服务器时，服务器会生成一个session，并将该sessionID发送给用户储存在cookie中，当后续发送请求时，sessionID就随着cookie一起发送，服务器就可以识别出是谁发送的请求。

cookie：用于存储服务器返回给客服端的信息，客户端进行保存。在下一次访问该网站时，客户端会将保存的cookie一同发给服务器

**cookie与session的区别**

1，**储存位置**：cookie储存在浏览器，session储存在服务器

2，**安全性**：session比cookie更加安全，cookie容易造成cookie欺骗

3，**存储的数据类型**不同：cookie只支持字符串数据，session可以储存任意类型数据、

4，**有效期**不同：cookie存活时间可设置较长时间，而session存活时间相对较短，服务端关闭等都会丢失session

5，**存储大小**不同：单个cookie的数据不能超过4KB，session储存的数据内容可以更大，但是session过多会占用更多的服务器资源

token：客户端访问服务端时，服务端根据客户端的信息生成的一串字符串，返回给客户端，后续客户端的请求就可以带上这个token用于身份验证

### 4.http缓存技术

对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都**缓存在本地浏览器**，下次直接读取，有效提高性能。缓存方式有两种

**强制缓存：**

只要浏览器判断缓存没有过期就直接从浏览器缓存过的本地进行读取，不会去请求服务器。

**协商缓存：**

协商缓存表示在使用本地的缓存之前，会先向服务器发一个请求，与服务器协商当前浏览器的缓存是否已经过期了，如果没过期，那么就使用本地的资源，如果过期了就去请求最新资源。协商缓存主要是解决强缓存资源不能及时更新的问题

### 5.Http协议特性 (优缺点)

**简单、灵活易于扩展**：请求方法、URI/URL、状态码、头字段等每个组成都允许开发人员自定义和扩充。

**跨平台**：电脑的浏览器和手机的各种app都能够使用，应用范围广泛。

**http是无状态的：**

- 不需要额外的资源来记录状态信息，这**能减轻服务器的负担**。
- 如果**后续处理需要前面的信息会非常麻烦**。例如添加购物车->下单->结算->支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。

**明文传输：**方便阅读，但信息暴露，不安全

### 6.HTTP/1.1、HTTP/2、HTTP/3演变

#### HTTP/1.1 相比 HTTP/1.0 

- 使用**长连接**的方式改善了 HTTP/1.0 短连接造成的性能开销
- 支持**管道（pipeline）网络传输**，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间，**但是以fifo的方式串行处理请求，当一个请求没有响应时，会产生队头阻塞**

#### HTTP/2的优化

- **头部压缩：**如果多个请求的header头是一样的或是相似的，那么，协议会**通过缓存表避免重复的部分传输，提高速度**。
- **二进制格式：**头信息和数据体都是二进制，并且统称为帧**（frame）：头信息帧和数据帧。对计算机友好，**增加了数据传输的效率
- **多路复用（并发传输）：**在同一个连接上使用请求和响应双向数据流，服务端可以并行交错的发送响应，解决了队头阻塞问题
- **服务器主动推送资源：**改善了传统的「请求-应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。

#### HTTP/3的优化

无队头阻塞：http/3使用UDP协议，不存在TCP上的队头阻塞

更快的连接建立：

连接迁移：

### 7.HTTP与HTTPS的区别

- HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 SSL/TLS 加密传输协议。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 TLS 的握手过程，才可进入加密报文传输。
- 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### 8.HTTPS原理

对称加密：加密密钥和解密密钥是相同的

非对称加密：使用两个密钥，公钥和私钥，公钥加密只能由私钥解密，私钥加密只能由公钥解密

**https使用的是混合加密的方式：**

- 采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

原理解析：

使用对称加密传输数据，密钥被拦截获取，信息就不安全了。因此使用非对称加密，生成一个不会被泄露的秘钥。

服务器将公钥发给客户端，客户端生成一个随机数并用公钥进行加密，发送给服务器，服务器收到后进行解密，如此通信双方得到了一个同样的随机数。这个随机数可以作为对称加密的秘钥对真正传递的数据进行加密。如果公钥被拦截获取了也没用，因为公钥无法解密客户端用公钥加密的数据。

如果公钥被被拦截获取并替换了，当客户端假公钥加密的随机数又被拦截，可以被替换者的私钥解密获取，又用拦截得来的服务器公钥对其加密发给服务端。服务器也得到了这个随机数。所以公钥必须表名自己的身份。

**数字证书**，服务器在CA机构注册自己的公钥，CA用自己的私钥对服务器的包含公钥的数据集合进行加密（签名），签名数据和原始数据集合构成数字证书发给服务器，服务器将数字证书发给客户端后，客户端可以用CA的公钥解密签名数据来确定数字证书的真实性。这样就**保证了公钥不是被替换的**。



<img src="C:\Users\lll\AppData\Roaming\Typora\typora-user-images\image-20240423171955500.png" alt="image-20240423171955500" style="zoom:67%;" />

#### TLS握手阶段

- clientHello：客户端发送自己支持的加密规则和生成的一个随机数给服务端
- SeverHello：服务端也发送确认的加密规则和生成的一个随机数以及数字证书给客户端
- 客户端验证证书的合法性，取出公钥，再生成一个随机数用公钥进行加密发送给服务器
- 服务器用私钥解析出这个随机数后，发送握手结束通知给客户端。

服务端和客户端用协商好的加密规则根据这三个随机数计算出本次通信使用的对称加密的会话秘钥

## TCP

### 1.TCP和UDP的区别

- TCP 面向连接，UDP 无连接；
- TCP 保证数据的可靠传输，数据传送**无重复，丢失，错误，失序**；
- TCP 连接一对一，UDP支持更广泛；
- UDP首部开销小只有8个字节，而TCP最少有20字节；
- TCP 面向数据流，UDP 面向数据报

### 2.三次握手过程

**三次握手**（Three-way Handshake）是指在建立一个TCP连接时，客户端和服务器会一共发送三个报文段。

- 初始时客户端和服务器都处于CLOSED状态，先是服务端主动监听某个端口，处于 `LISTEN` 状态

- **第一次握手：**客户端向服务端发送一个SYN报文，其中标志位syn位置1，另外初始化首部中的序列号seq=x，此时客户端进入同步已发送状态（SYN_SENT）
- **第二次握手：**服务端接收到SYN报文后，会发送一个SYN_ACK报文，其中标志位SYN置1，确认字段为x+1，初始化首部中的序列号seq=y，此时服务器出于同步已接收状态
- **第三次握手**：客户端收到SYN_ACK报文后，会发送一个ACK报文，序号seq=x+1，确认号ack=y+1。此时客户端进入established状态。

- 服务端收到ACK报文后，也进入established状态。然后，tcp连接就建立起来了。

**注意：第一次握手和第二次握手都只是消耗掉一个序号，但不能携带数据；第三次握手可以携带数据。**

### 3.为什么是三次握手，不能是二次握手？

- **避免历史连接：**防止客户端旧的重复的SYN报文建立连接造成混乱
- **同步双方初始序列号：**TCP协议的通信双方， 都必须维护一个序列号， 序列号是可靠传输的一个关键因素，三次握手在能确保双方序号都被可靠的同步。
- **避免不必要的资源浪费：**当客户端发生的 `SYN` 报文在网络中阻塞，客户端就会重新发送 `SYN` ，由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 `ACK` 报文，所以服务端每收到一个 `SYN` 就只能先主动建立一个连接

### 4.为什么每次建立tcp连接，建立的序列号都不一样？

如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文大概率遇到历史报文的序列号刚好在对方的接收窗口内，于是被这个连接接收的问题。

### 5.四次挥手过程

四次挥手也就是客户端与服务器断开连接时，需要一共发送四个报文段来完成断开TCP连接。

初始时，客户端与服务器都处于ESTABLISHED状态，假如客户端或服务端发起断开连接的请求

- 第一次挥手：首先客户端发送FIN报文，指定序号seq=u。客户端进入fin_wait_1状态

- 第二次挥手：服务端收到FIN报文后，立即发送一个ACK报文，确认号为ack=u+1，初始化序号seq=v，进入close_wait状态

  在二三次挥手之间，还是半关闭状态，数据还是可以从服务器传到客户端

- 第三次挥手：如果数据传送完毕，服务器想断开连接，就发送一个FIN报文，并重新制定一个序号seq=w，确认号还是ack=u+1，进入last_ack状态

- 第四次挥手：客户端接收到FIN报文，一样发出ACK应答，序号seq=u+1，确认号为ack=w+1，客户端进入time_wait状态，需要经过一段时间确保服务器收到自己的应答报文后，才会进入CLOSED状态。

### 6.为什么是四次挥手，而中间两次不能一起？

服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

### 7.为什么要需要TIME_WAIT？为什么等待2MSL？

- 客户端必须等待足够长的时间，确保服务端能够收到ACK，使得其能够正常关闭

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，若ACK在一个MSL内丢失，这样被动方重发的 FIN 会在第 2 个MSL内到达，TIME_WAIT 状态的连接可以应对。

### 8.TCP重传、滑动窗口、流量控制、拥塞控制

#### TCP重传

超时重传：在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据

快重传：当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

#### 滑动窗口

TCP每发送一个数据，都要进行一次确认应答，效率低下。窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

# golang

## 基础（函数/语法/细节）

### go语言特色

#### go的优势

- Go **代码的设计是务实的**。每个功能和语法决策都旨在让程序员的生活更轻松。
- Golang 针对**并发**进行了优化，并且在规模上运行良好。
- 由于单一的标准代码格式，Golang 通常被认为比其他语言更具**可读性**。
- **自动垃圾收集**明显比 Java 或 Python 更有效，因为它与程序同时执行。

#### go有哪些很不错的地方（举例/具体）

### golang数据类型

基本数据类型：int/byte/rune/float64/complex6，string，boolean

结构体，数组

切片slice，map，channel，函数function，指针pointer，Interface

### 各数据类型是否可以比较

**除了基本数据类型外的其他类型最多只能使用==和!=进行比较**

#### **基本数据类型**

整数、浮点数、复数支持==和!=比较，除了复数外，其余的数值类型还可以使用 < 、> 、<= 和 >= 进行大小比较。

字符串是基于字典序进行比较的，因此也可以使用 < 、> 、<= 和 >= 来比较大小。

布尔值可以使用 == 和 != 进行比较

#### **数组**

**数组长度相同**的时候，这两个数组才是可比较==和!=的。数组间的比较是逐个元素进行的，一旦遇到不相等的元素则停止比较并返回false

#### **结构体**

如果结构体的**所有字段都是可比较的**，则该结构体类型也是可比较的

#### **指针**

可以比较，比较的是存储的内存地址是否相同，即两个指针是否指向同一个变量

#### interface

接口的动态值为可比较类型并且具体类型一致时，才可进行比较

#### 切片/映射/通道/函数

切片（slice）、映射（map）、函数（func）、通道（chan），不可比较，除了与 nil 进行比较之外

### 数组是如何实现根据下标随机访问数组元素的？

- 计算机给数组a，分配了一组连续的内存空间。
- 比如内存块的首地址为 base_address=1000。
- 当计算给每个内存单元分配一个地址，计算机通过地址来访问数据。当计算机需要访问数组的某个元素的时候，会通过一个寻址公式来计算存储的内存地址。

### 深拷贝和浅拷贝

深拷贝：创造一个新对象，只拷贝数据，新创建的对象与原对象不共享内存

浅拷贝：拷贝的是数据地址，只复制指向的对象的指针，新老对象指向同一个内存

### make和new的区别

两个内置函数都用来为变量分配内存

- make 只能用来分配及初始化类型为slice、map、chan 的数据。new 可以分配任意类型的数据；

- new 返回类型是指针，即类型 *Type。make返回引用，即 Type；
- new 直接置为零值。make分配空间后，会初始化slice, map, channel等内置数据结构；

### 结构体

#### 空结构体

使用unsafe.SizeOf()知道空结构体不占任何空间，所有空结构体都是同一个地址

使用场景：

- 实现集合类型set，`type set map[string]struct{}`节省空间
- 空通道chan struct{}，用于协调Goroutine的运行
- 作为方法接收者

**只用占位不用实际含义，那么我们就都可以使用空结构体**，可以极大的节省不必要的内存开销。

### interface

能不能比较

### defer

#### 应用场景

函数调用结束后，完成一些收尾工作，例如在defer中回滚数据库的事务

### Context

#### context包的作用

- 上下文信息传递 WithValue

- 控制子 goroutine 的运行
- 超时控制的方法调用 WithTimeOut
- 可以取消的方法调用 WithCancel

## 切片

### 底层实现

```go
type slice struct {
	array unsafe.Pointer	//指向底层数组的指针
	len int					//切片长度
	cap int					//切片容量
}
```

- 指针：指向 slice 可以访问到的第一个元素。
- 长度：slice 中元素个数。
- 容量（底层数组长度）： slice 起始元素到**底层数组**最后一个元素间的元素个数。

### 数组和切片的区别

- 数组是值类型，而切片是引用类型，其底层数据结构包含一个数组，切片也可以被看作对数组某一连续片段的引用
- 切片的容量会动态变化，而数组的长度和容量始终相等

### 扩容机制

在执行append操作追加若干元素的时候，如果切片没有足够的容量来容纳这些元素，那么就会扩容，具体流程为

- 根据**扩容原理**确定新切片的容量，
- 创建一个新的切片
- 将旧切片的元素和追加的元素复制到新的切片中，
- 切片的引用会指向新的底层数组，原数组会被垃圾回收。

#### Go 1.18版本之前扩容原理

**1.** 如果期望容量大于当前容量的两倍就会使用期望容量；

**2**. 否则如果当前切片的长度小于 1024 就会将容量翻倍；

**3.** 如果当前切片的长度大于等于 1024 就会循环增加 25% 的容量，直到新容量大于期望容量；

#### Go 1.18版本之后扩容原理

**1.** 如果期望容量大于当前容量的两倍就会使用期望容量；

**2.** 如果当前切片的长度小于阈值（默认 256）就会将容量翻倍；

**3.** 如果当前切片的长度大于等于阈值（默认 256），就会循环增加 25% 的容量，基准是 newcap + 3*threshold，直到新容量大于期望容量；

**Go的设计者不断优化切片扩容的机制，其目的只有一个：就是控制让小的切片容量增长速度快一点，减少内存分配次数，而让大切片容量增长率小一点，更好地节省内存。**

### 切片有什么坑？原理是什么

多个切片指向同一个地址，当某一个切片执行append操作发生了扩容，那么它指向的地址会改变

## map

### 底层实现

#### 概括

map的底层是一个hmap结构体。里面包含了一个**桶数组**。每个桶都是一个bmap的结构体，每个元素都可以存8个键值对，首先通过哈希函数计算出哈希值，对哈希值取模（哈希值低B位）找到对应的桶，在这个桶和溢出桶链表中（tophash哈希值高8位）找到key的位置，插入元素和读元素。

```go
// go 1.17
type hmap struct {
    count      int            //元素个数，调用len(
    map)时直接返回
    flags      uint8          //标志是否正在写map，并发操作会返回fatalerror
    B          uint8          //桶(buckets)的对数 B=5表示能容纳32个元素
    noverflow  uint16        //桶(buckets)溢出数量，如果一个单元能存8个key，此时存储了9个，溢出了，就需要再增加一个桶
    hash0      uint32         //哈希种子
    buckets    unsafe.Pointer //指向桶(buckets)数组,大小为2^B，可以为nil
    oldbuckets unsafe.Pointer //扩容的时候，buckets长度会是oldbuckets的两倍
    nevacute   uintptr        //指示扩容进度，小于此buckets迁移完成
    extra      *mapextra      //与gc相关 可选字段
}
```

```go
// A bucket for a Go map.
type bmap struct {
	tophash [bucketCnt]uint8
}
//实际上编译期间会生成一个新的数据结构
type bmap struct {
    topbits  [8]uint8     //哈希值高8位
    keys     [8]keytype	  //key
    values   [8]valuetype //value
    pad      uintptr
    overflow uintptr      //下一个桶的地址
}
```

<img src="assets/1648976018069-e8483366-3316-48c0-98c9-09a54f94a230.png" alt="img" style="zoom: 50%;" />

#### 读流程

通过哈希函数计算出哈希值->哈希值对桶的数量取模求出索引的位置->遍历桶和溢出桶链表和其中的8个槽位找到key所在的位置->没找到返回零值，找到返回val

桶中包含8个键值对和8个tophash（hash值高8位）用于读的时候判断是不是这个位置。

#### 写流程

![map](assets/map.png)

### 扩容机制

map有两种扩容机制：装载系数或溢出桶数量增加

- **翻倍扩容**：装载因子超过6.5（平均每个槽6.5个key），数据太多影响map操作的效率。创建一个新的bucket，新的bucket长度是原来的2倍，然后旧bucket数据搬迁到新的bucket。
- **等量扩容**：溢出桶的数量超过了普通桶，只迁移数据而不扩大容量，把松散的键值对重新排列一次，使数据更加的紧凑，进而保证更快的存取

**渐进式扩容**：对桶进行操作时才进行部分数据的迁移，避免一次性全部数据迁移引发性能抖动

### key可以是哪些类型？可以嵌套map吗？

key不能是：map，切片，函数

可以嵌套map

### map是线程安全的吗？

**线程安全**：多个线程进行并发读写时，程序可以正常运行并得到预期结果

Map不是并发安全的，并发读写时程序会panic。

**线程安全的map实现：**

- 使用sync包加读写锁
- 使用官方的线程安全的map，sync.Map

### map的遍历顺序

map可以通过`for range map`进行遍历，但是每一次遍历的顺序是不一致的，这是因为遍历时底层会生成一个随机数来决定从哪里开始遍历

### sync.Map的原理以及与普通map的性能比较



## 反射2

## 泛型

## 并发编程

### 进程、线程和协程

进程（process）：程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。

线程（thread）：操作系统基于进程开启的轻量级进程，是操作系统调度执行的最小单位。

协程（coroutine）：非操作系统提供而是由用户自行创建和控制的用户态‘线程’，比线程更轻量级

### goroutine调度

## 垃圾回收 GC

## GMP
