

### mq理论

##### mq简介

### rabbitmq

# temp

## kafka

#### kafka入门

##### 消息队列

**Kafka 是消息队列的一种实现**，类似的还有**RocketMQ** 和 **RabbitMQ**。Kafka 不论是在实践中还是在面试中，都是热点。

消息队列的基本形态，就是有 N 个生产者， N 个消费者。在这种形态下，**生产者和消费者就解耦**了。

##### 基本概念

**producer**：生产者，生产者发送消息到指定的topic下，消息再根据分配规则append到某个分区的末尾。

**consumer**：消费者，消费者从topic中消费数据。

**broker**：kafka 集群包含一个或多个服务器，每个服务器节点称为一个broker。

**topic**：每条发布到kafka集群的消息都有一个类别，这个类别称为topic，其实就是将消息按照topic来分类，topic就是逻辑上的分类，同一个topic的数据既可以在同一个broker上也可以在不同的broker结点上。

**partition**：分区，每个topic被物理划分为一个或多个分区，每个分区在物理上对应一个文件夹，该文件夹里面存储了这个分区的所有消息和索引文件。

**offset**：partition中的每条消息都被标记了一个序号，这个序号表示消息在partition中的偏移量，称offset，每一条消息在partition都有唯一的offset，消息者通过指定offset来指定要消费的消息

**消费者组**：每个消费者都属于一个特定的消费者组

![image-20240923164600309](D:\E\学习\Go\笔记\技术栈\assets\image-20240923164600309.png)

##### 分区策略

分区策略就是决定生产者将消息发送到哪个分区的算法。Kafka 为我们提供了默认的分区策略，同时它也支持自定义分区策略。kafka允许为每条消息设置一个key，一旦消息被定义了 Key，那么就可以保证同一个 Key 的所有消息都进入到相同的分区。

除了根据key选择分区，还有

• 轮询：一个分区发送一次，挨个轮流。

• 随机：随机挑选一个。

##### 分区消息有序性

同一分区中的数据是有序的，但topic下的多个分区之间在消费数据时不能保证有序性，

**因此，如果要做到全局有序，topic就只能有一个分区。**

![image-20240923165130091](D:\E\学习\Go\笔记\技术栈\assets\image-20240923165130091.png)

##### 消费者组

topic的一条消息只能被消费者组内的一个consumer消费，但其他消费者组的消费这可同时消费这一分区消息。**也就是一个分区不能给同一个组内的多个消费者使用**

这也是kafka用来实现一个topic消息的广播和单播的手段，**如果需要实现广播，一个consumer group内只放一个消费者即可，要实现单播，将所有的消费者放到同一个consumer group即可。**

#### kafka api使用

##### Docker 启动 Kafka

正常来说，可以直接使用 Docker 来启动 Kafka。Kafka 早期的版本需要一个额外的 ZooKeeper，但是高版本已经不需要了。

```
kafka:
  image: 'm.daocloud.io/docker.io/bitnami/kafka:latest'
  ports:
    - '9092:9092'
    - '9094:9094'
  environment:
    - KAFKA_CFG_NODE_ID=0
    #      - 允许自动创建 topic，线上不要开启
    - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    - KAFKA_CFG_PROCESS_ROLES=controller,broker
    - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://:9093,EXTERNAL://0.0.0.0:9094
    - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
    - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
    - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
    - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
```

##### Kafka 的 Shell 工具

正常为了调试 Kafka，或者说为了在写代码的时候验证消息有没有发出去、topic 有没有建立起来，都是可以考虑使用 Kakfa 的 Shell 工具。

在启动了 Docker 之后，运行命令，其中ID 替换为 Docker Compose 启动之后对应的 Kafka 的 ID。 

```
dockerexec -it $id /bin/sh。
docker exec -it c8d536f693cc3d6df8ec71ec6c6807504599360347917e54ec72d477f05eccf8 /bin/sh
```

而后切换目录到 /opt/bitnami/kafka/bin 下，就可以了。

**Kafka Shell 工具常用命令**

查看kafka shell文档即可

##### Sarama 安装

在 Go 里面有三个比较有名气的 **Go 客户端。**

• **Sarama**：用户数量最多，但是有一些 BUG（个人认为是因为用户多 BUG 才暴露得比较清晰，我没怎么遇到过），早期这个项目是在 Shopify 下面，现在挪到了 IBM 下。

• **segmentio/kafka-go**：没啥大的缺点。

• **confluent-kafka-go**：需要启用 cgo，跨平台问题比较多，交叉编译也不支持。这里我们选用 Sarama，因为用户多，你出去工作接触到它的概率最大

###### Sarama shell命令工具

在 Sarama 里面提供了一些简单的命令行工具，可以看做是 Shell 脚本提供的功能一个子集。Consumer 和 producer 中的用得比较多。

安装使用sarama sell工具命令：

```
go install github.com/IBM/sarama/tools/kafka-console-consumer@latest
go install github.com/IBM/sarama/tools/kafka-console-producer@latest
```

启动一个消费者

```
kafka-console-consumer -topic=test_topic -brokers=localhost:9094
```



##### 生产者发送消息

导包

```
"github.com/IBM/sarama"
```

发送一个消息很简单，只需要初始化好producer，然后直接发送消息就可以。可以使用 Sarama 的 kafka-console-consumer启动一个消费者消费来查看是否发送成功。

###### 简单使用

```go
func TestSyncProducer(t *testing.T) {
   cfg := sarama.NewConfig()
   cfg.Producer.Return.Successes = true
   //指定分区策略，默认是hash
   cfg.Producer.Partitioner = sarama.NewHashPartitioner
   producer, err := sarama.NewSyncProducer(addr, cfg)
   assert.NoError(t, err)
   for i := 0; i < 100; i++ {
      _, _, err = producer.SendMessage(&sarama.ProducerMessage{
         Topic: "test_topic",
         //消息数据本体
         Value: sarama.StringEncoder("这是一条消息"),
         //会在生产者和消费者之间传递的
         Headers: []sarama.RecordHeader{
            {
               Key:   []byte("key1"),
               Value: []byte("value1"),
            },
         },
         //只作用于发送过程
         Metadata: "这是 metadata",
      })
   }
}
```

###### **指定分区**

在 Sarama 里面，可以通过指定 config 中的 Partitioner 来指定最终的目标分区。下列出了常见的： • Random：随机挑一个。 • RoundRobin：轮询。 • Hash：根据 key 的哈希值来筛选一个。 • Manual：根据 Message 中的 partition 字段来选择。 • ConsistentCRC：一致性哈希，用的是 CRC16 算法。 • Custom：实际上不 Custom，而是自定义一部分Hash 的参数，本质上是一个 Hash 的实现。

```
cfg.Producer.Partitioner = sarama.NewHashPartitioner
```

###### **异步发送**

Sarama 有一个异步发送的 producer，它的用法稍微复杂一点。

• 把 Return.Success 和 Errors 都设置为true，这是为了后面能够拿到发送结果。

• 初始化异步 producer。

• 从 producer 里面拿到 Input 的 channel，并且发送一条消息。

• 利用 select case，同时监听 Success 和 Error 两个channel，来获得发送成功与否的信息。

```go
func TestAsyncProducer(t *testing.T) {
   cfg := sarama.NewConfig()
   cfg.Producer.Return.Successes = true
   cfg.Producer.Return.Errors = true
   producer, err := sarama.NewAsyncProducer(addr, cfg)
   assert.NoError(t, err)
   msgs := producer.Input()
   msgs <- &sarama.ProducerMessage{
      Topic: "test_topic",
      Value: sarama.StringEncoder("这是一条消息"),
      // 会在生产者和消费者之间传递的
      Headers: []sarama.RecordHeader{
         {
            Key:   []byte("key1"),
            Value: []byte("value1"),
         },
      },
      Metadata: "这是 metadata",
   }

   select {
   case msg := <-producer.Successes():
      t.Log("发送成功", string(msg.Value.(sarama.StringEncoder)))
   case err := <-producer.Errors():
      t.Log("发送失败", err.Err, err.Msg)
   }
}
```

###### 指定 acks

在 Kafka 里面，生产者在发送数据的时候，有一个很关键的参数，就是 acks。有三个取值：

• 0：客户端发一次，**不需要服务端的确认。**

• 1：客户端发送，并且**需要服务端写入到主分区。**

• -1：客户端发送，并且**需要服务端同步到所有的ISR(从分区)上。**

从上到下，性能变差，但是数据可靠性上升。需要性能，选 0，需要消息不丢失，选 -1。

##### 消费者获取消息

###### 初步实现

Sarama 的消费者设计不是很直观，稍微有点复杂。

• 首先要初始化一个 ConsumerGroup。 • 调用 ConsumerGroup 上的 Consume 方法。 • 为 Consume 方法传入一个 ConsumerGroupHandler的辅助方法。

必须要自己实现一个consumeHandle

```go
func TestConsumer(t *testing.T) {
   cfg := sarama.NewConfig()
   cg, err := sarama.NewConsumerGroup(addr, "demo", cfg)
   assert.NoError(t, err)
   ctx, cancel := context.WithTimeout(context.Background(), time.Minute*10)
   defer cancel()
   start := time.Now()
   //阻塞调用
   err = cg.Consume(ctx, []string{"test_topic"}, ConsumerHandler{})
   assert.NoError(t, err)
   t.Log(time.Since(start).String())
}
type ConsumerHandler struct {
}

func (c ConsumerHandler) Setup(session sarama.ConsumerGroupSession) error {
   log.Println("这是 Setup")
   //partitions := session.Claims()["test_topic"]
   //for _, part := range partitions {
   // session.ResetOffset("test_topic",
   //    part, sarama.OffsetOldest, "")
   //}
   return nil
}

func (c ConsumerHandler) Cleanup(session sarama.ConsumerGroupSession) error {
   log.Println("这是 Cleanup")
   return nil
}

func (c ConsumerHandler) ConsumeClaim(session sarama.ConsumerGroupSession,
    claim sarama.ConsumerGroupClaim) error {
    msgs := claim.Messages()
    for msg := range msgs {
        log.Println(string(msg.Value))
        session.MarkMessage(msg, "")
    }
    return nil
}
```

###### 指定偏移量消费

在部分场景下，我们会希望消费历史消息，或者从某个消息开始消费，那么可以考虑在 Setup 里面设置偏移量。关键调用是 ResetOffset 。不过一般我都是建议走离线渠道，操作 Kafka 集群去重置对应的偏移量。核

心在于，你并不是每次重新部署，重新启动都是要重置这个偏移量的。

```
func (c ConsumerHandler) Setup(session sarama.ConsumerGroupSession) error {
   log.Println("这是 Setup")
   partitions := session.Claims()["test_topic"]
   for _, part := range partitions {
      session.ResetOffset("test_topic",
         part, sarama.OffsetOldest, "")
   }
   return nil
}
```

###### 异步消费，批量提交

**通过gorouinte进行消息的处理，实现异步消费**

正常来说，为了在异步消费失败之后还能继续重试，可以考虑**异步消费一批，提交一批。**

ctx.Done 分支用来控制凑够一批的超时机制，防止生产者的速率很低，一直凑不够一批。另外一个分支就是读取消息，并且提交到 errgroup 里面执行。

Sleep 是模拟长时间业务执行。

```
func (c ConsumerHandler) ConsumeClaim(
   //代表的是和kafka的会话（从建立连接到连接彻底断掉的那一段时间）
   session sarama.ConsumerGroupSession,
   claim sarama.ConsumerGroupClaim) error {

   msgCh := claim.Messages()
   const batchSize = 10
   for {
      log.Println("一个批次开始")
      batch := make([]*sarama.ConsumerMessage, 0, batchSize)
      //凑够一批的时间不能超过1s
      ctx, cancel := context.WithTimeout(context.Background(), time.Second)
      var done = false
      var eg errgroup.Group
      for i := 0; i < batchSize && !done; i++ {
         select {
         case <-ctx.Done():
            // 超时了
            done = true
         case msg, ok := <-msgCh:
            //消费者被关闭了
            if !ok {
               cancel()
               return nil
            }
            batch = append(batch, msg)
            eg.Go(func() error {
               // 并发处理
               log.Println(string(msg.Value))
               return nil
            })
         }
      }
      cancel()
      err := eg.Wait()
      if err != nil {
         log.Println(err)
         continue
      }
      // 凑够了一批，然后你就处理
      // log.Println(batch)

      for _, msg := range batch {
         session.MarkMessage(msg, "")
      }
   }
}
```
